import os
import functools
import operator
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.messages import BaseMessage, HumanMessage
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END
from langchain.tools import tool
from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict
from langchain_core.tools import tool
from typing import Annotated
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.memory import ConversationBufferMemory
from sqlalchemy import create_engine, MetaData
from langchain_community.utilities import SQLDatabase
# from langchain.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_openai import ChatOpenAI
from langchain_community.agent_toolkits.sql.prompt import SQL_FUNCTIONS_SUFFIX
from langchain_core.messages import AIMessage, SystemMessage
from langchain_core.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,)
from dotenv import load_dotenv

load_dotenv()

# Set up PostgreSQL connection
postgres_config = {
    "user": "postgres",
    "password": "KS4pBcm9MfHuy",
    "host": "database-1.c7o0o6mq64fi.us-east-1.rds.amazonaws.com",
    "port": "5432",
    "database": "db_ra"
}

# os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Review Attendent"
os.environ["TAVILY"]=os.getenv('TAVILY_API_KEY')

# Initialize model
llm = ChatOpenAI(model="gpt-3.5-turbo",
                  openai_api_key=os.getenv('OPENAI_API_KEY'))

tavily_tool = TavilySearchResults(max_results=5)

@tool
def db_tool(messages):
    """
    This function utilizes a database to process a given list of messages.
 
    Args:
        messages: A list of messages to be processed by the database tool.
 
    Returns:
        The output generated by the database tool after processing the messages.
    """
    db_engine = create_engine(f"postgresql://{postgres_config['user']}:{postgres_config['password']}@{postgres_config['host']}:{postgres_config['port']}/{postgres_config['database']}")
    db = SQLDatabase(db_engine)
    toolkit = SQLDatabaseToolkit(db=db, llm=llm)
    context = toolkit.get_context()
    prompt = ChatPromptTemplate.from_messages([
        HumanMessagePromptTemplate.from_template("{messages}"),
        AIMessage(content=SQL_FUNCTIONS_SUFFIX),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ]).partial(**context)
    db_agent = create_openai_tools_agent(llm, toolkit.get_tools(), prompt)
    executor = AgentExecutor(agent=db_agent, tools=toolkit.get_tools(), memory=memory)
    result = executor({"messages": messages})
    return result["output"]
 
tools = [tavily_tool, db_tool]
 
# Create a memory object
memory = ConversationBufferMemory(input_key='messages')
 
# Helper function for creating agents
def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str, memory=None):
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        MessagesPlaceholder("messages", optional=True),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    agent = create_openai_tools_agent(llm, tools, prompt)
    executor = AgentExecutor(agent=agent, tools=tools, memory=memory)
    return executor
 
# Define agent nodes
def agent_node(state, agent, name):
    result = agent.invoke(state)
    return {"messages": [HumanMessage(content=result["output"], name=name)]}
 
# Create Agent Supervisor
members = ["DB_Agent", "Web_Agent"]
system_prompt = (
    "As a supervisor, your role is to oversee a dialogue between these"
    " workers: {members}. You are a helpful AI assistant, collaborating with other assistants."
    " Use the provided tools to progress towards answering the user's query. Based on the user's request,"
    " determine which worker should take the action. The DB Agent is responsible for"
    " checking if the query can be answered using the database, such as retrieving latest reviews, average ratings, or specific review details."
    " If the query is related to retrieving latest reviews, average ratings, or specific review details, popular food items, or menu items, assign it to the DB Agent."
    " If not, it will pass the query to the Web Agent."
    " The Web Agent is responsible for searching the web using Tavily and providing relevant information to answer the query."
    " Collect the results from the responsible agent and format them into a final response for the user."
    " Once tasks are completed,"
    " indicate with 'FINISH' and share the final and accurate result."
)
 
options = ["FINISH"] + members
function_def = {
    "name": "route",
    "description": "Select the next role.",
    "parameters": {
        "title": "routeSchema",
        "type": "object",
        "properties": {"next": {"title": "Next", "anyOf": [{"enum": options}] }},
        "required": ["next"],
    },
}
 
prompt = ChatPromptTemplate.from_messages([
  ("system", system_prompt),
  MessagesPlaceholder(variable_name="messages"),
  ("system", "Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}"),
]).partial(options=str(options), members=", ".join(members))
 
supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call="route") | JsonOutputFunctionsParser())
 
# Creating the DB Agent
db_agent = create_agent(llm, tools,""" You are a Database Agent. Your primary task is to accurately retrieve and analyze information from the database based on the user's query.
The database contains data such as reviews, ratings, food sentiment, drink sentiment and other relevant details. You should use this data to respond to the user's queries.
If the user's query cannot be answered using the database, you should politely indicate that and pass the query to the Web Agent for further assistance.
Your responses should be concise, accurate, and directly address the user's query based on the available data in the database. """,  memory=memory)
 
db_agent_node = functools.partial(agent_node, agent=db_agent, name="DB_Agent")
 
# Creating the web Agent
web_agent = create_agent(llm, tools, "You are a Web Agent. Your task is to answer the query from web search using tavily for providing relevant and up to date information. Use the provided search results to generate a comprehensive answer.", memory=memory)
web_agent_node = functools.partial(agent_node, agent=web_agent, name="Web_Agent")
 
# Define the Agent State, Edges and Graph
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    next: str
 
workflow = StateGraph(AgentState)
workflow.add_node("DB_Agent", db_agent_node)
workflow.add_node("Web_Agent", web_agent_node)
workflow.add_node("supervisor", supervisor_chain)
 
# Define edges
for member in members:
    workflow.add_edge(member, "supervisor")
 
conditional_map = {k: k for k in members}
conditional_map["FINISH"] = END
workflow.add_conditional_edges("supervisor", lambda x: x["next"], conditional_map)
workflow.set_entry_point("supervisor")
 
graph = workflow.compile()
 
 
## Run graph
def run_graph(query):
    initial_state = {
        "messages": [
            HumanMessage(content=query)
        ]
    }
    result = {}
    for st in graph.stream(initial_state):
        if "__end__" not in st:
            print(st)
            print('___________')
            result.update(st)
    return st, result

ip=input('enter your question fool: ')
st, final_ip=run_graph(ip)

# print('\n\n')
# print(final_ip['Web_Agent']['messages'][0].content)
# print('\n\n')
