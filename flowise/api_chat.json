{
  "nodes": [
    {
      "id": "recursiveCharacterTextSplitter_0",
      "position": {
        "x": -774.6651692177754,
        "y": -104.1716315278492
      },
      "type": "customNode",
      "data": {
        "id": "recursiveCharacterTextSplitter_0",
        "label": "Recursive Character Text Splitter",
        "version": 2,
        "name": "recursiveCharacterTextSplitter",
        "type": "RecursiveCharacterTextSplitter",
        "baseClasses": [
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "default": 1000,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number"
          },
          {
            "label": "Custom Separators",
            "name": "separators",
            "type": "string",
            "rows": 4,
            "description": "Array of custom separators to determine when to split the text, will override the default separators",
            "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
            "additionalParams": true,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-separators-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": "800",
          "chunkOverlap": "80",
          "separators": ""
        },
        "outputAnchors": [
          {
            "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "recursiveCharacterTextSplitter",
            "label": "RecursiveCharacterTextSplitter",
            "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
            "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 430,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -774.6651692177754,
        "y": -104.1716315278492
      }
    },
    {
      "id": "huggingFaceInferenceEmbeddings_0",
      "position": {
        "x": -119.98797320346651,
        "y": -140.343325153193
      },
      "type": "customNode",
      "data": {
        "id": "huggingFaceInferenceEmbeddings_0",
        "label": "HuggingFace Inference Embeddings",
        "version": 1,
        "name": "huggingFaceInferenceEmbeddings",
        "type": "HuggingFaceInferenceEmbeddings",
        "baseClasses": [
          "HuggingFaceInferenceEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "HuggingFace Inference API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "huggingFaceInferenceEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "modelName",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "sentence-transformers/distilbert-base-nli-mean-tokens",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-modelName-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/sentence-transformers/all-MiniLM-L6-v2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-endpoint-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "sentence-transformers/all-MiniLM-L6-v2",
          "endpoint": ""
        },
        "outputAnchors": [
          {
            "id": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
            "name": "huggingFaceInferenceEmbeddings",
            "label": "HuggingFaceInferenceEmbeddings",
            "description": "HuggingFace Inference API to generate embeddings for a given text",
            "type": "HuggingFaceInferenceEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 473,
      "selected": false,
      "positionAbsolute": {
        "x": -119.98797320346651,
        "y": -140.343325153193
      },
      "dragging": false
    },
    {
      "id": "postgres_0",
      "position": {
        "x": 528.6582274711285,
        "y": -264.55569307567583
      },
      "type": "customNode",
      "data": {
        "id": "postgres_0",
        "label": "Postgres",
        "version": 4,
        "name": "postgres",
        "type": "Postgres",
        "baseClasses": [
          "Postgres",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity search upon query using pgvector on Postgres",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "PostgresApi"
            ],
            "id": "postgres_0-input-credential-credential"
          },
          {
            "label": "Host",
            "name": "host",
            "type": "string",
            "id": "postgres_0-input-host-string"
          },
          {
            "label": "Database",
            "name": "database",
            "type": "string",
            "id": "postgres_0-input-database-string"
          },
          {
            "label": "Port",
            "name": "port",
            "type": "number",
            "placeholder": "6432",
            "optional": true,
            "id": "postgres_0-input-port-number"
          },
          {
            "label": "Table Name",
            "name": "tableName",
            "type": "string",
            "placeholder": "documents",
            "additionalParams": true,
            "optional": true,
            "id": "postgres_0-input-tableName-string"
          },
          {
            "label": "Additional Configuration",
            "name": "additionalConfig",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "postgres_0-input-additionalConfig-json"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "postgres_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "postgres_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "postgres_0-input-embeddings-Embeddings"
          },
          {
            "label": "Record Manager",
            "name": "recordManager",
            "type": "RecordManager",
            "description": "Keep track of the record to prevent duplication",
            "optional": true,
            "id": "postgres_0-input-recordManager-RecordManager"
          }
        ],
        "inputs": {
          "document": [
            "{{apiLoader_0.data.instance}}"
          ],
          "embeddings": "{{huggingFaceInferenceEmbeddings_0.data.instance}}",
          "recordManager": "{{postgresRecordManager_0.data.instance}}",
          "host": "viaduct.proxy.rlwy.net",
          "database": "railway",
          "port": "40684",
          "tableName": "documents2",
          "additionalConfig": "",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "postgres_0-output-retriever-Postgres|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Postgres Retriever",
                "description": "",
                "type": "Postgres | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "postgres_0-output-vectorStore-Postgres|VectorStore",
                "name": "vectorStore",
                "label": "Postgres Vector Store",
                "description": "",
                "type": "Postgres | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 803,
      "selected": false,
      "positionAbsolute": {
        "x": 528.6582274711285,
        "y": -264.55569307567583
      },
      "dragging": false
    },
    {
      "id": "postgresRecordManager_0",
      "position": {
        "x": 203.3963175306801,
        "y": -167.5152079120309
      },
      "type": "customNode",
      "data": {
        "id": "postgresRecordManager_0",
        "label": "Postgres Record Manager",
        "version": 1,
        "name": "postgresRecordManager",
        "type": "Postgres RecordManager",
        "baseClasses": [
          "Postgres RecordManager",
          "RecordManager"
        ],
        "category": "Record Manager",
        "description": "Use Postgres to keep track of document writes into the vector databases",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "PostgresApi"
            ],
            "id": "postgresRecordManager_0-input-credential-credential"
          },
          {
            "label": "Host",
            "name": "host",
            "type": "string",
            "id": "postgresRecordManager_0-input-host-string"
          },
          {
            "label": "Database",
            "name": "database",
            "type": "string",
            "id": "postgresRecordManager_0-input-database-string"
          },
          {
            "label": "Port",
            "name": "port",
            "type": "number",
            "placeholder": "5432",
            "optional": true,
            "id": "postgresRecordManager_0-input-port-number"
          },
          {
            "label": "Additional Connection Configuration",
            "name": "additionalConfig",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "postgresRecordManager_0-input-additionalConfig-json"
          },
          {
            "label": "Table Name",
            "name": "tableName",
            "type": "string",
            "placeholder": "upsertion_records",
            "additionalParams": true,
            "optional": true,
            "id": "postgresRecordManager_0-input-tableName-string"
          },
          {
            "label": "Namespace",
            "name": "namespace",
            "type": "string",
            "description": "If not specified, chatflowid will be used",
            "additionalParams": true,
            "optional": true,
            "id": "postgresRecordManager_0-input-namespace-string"
          },
          {
            "label": "Cleanup",
            "name": "cleanup",
            "type": "options",
            "description": "Read more on the difference between different cleanup methods <a target=\"_blank\" href=\"https://js.langchain.com/docs/modules/data_connection/indexing/#deletion-modes\">here</a>",
            "options": [
              {
                "label": "None",
                "name": "none",
                "description": "No clean up of old content"
              },
              {
                "label": "Incremental",
                "name": "incremental",
                "description": "Delete previous versions of the content if content of the source document has changed. Important!! SourceId Key must be specified and document metadata must contains the specified key"
              },
              {
                "label": "Full",
                "name": "full",
                "description": "Same as incremental, but if the source document has been deleted, it will be deleted from vector store as well, incremental mode will not."
              }
            ],
            "additionalParams": true,
            "default": "none",
            "id": "postgresRecordManager_0-input-cleanup-options"
          },
          {
            "label": "SourceId Key",
            "name": "sourceIdKey",
            "type": "string",
            "description": "Key used to get the true source of document, to be compared against the record. Document metadata must contains SourceId Key",
            "default": "source",
            "placeholder": "source",
            "additionalParams": true,
            "optional": true,
            "id": "postgresRecordManager_0-input-sourceIdKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "host": "viaduct.proxy.rlwy.net",
          "database": "railway",
          "port": "40684",
          "additionalConfig": "",
          "tableName": "upsertion_records2",
          "namespace": "api_collection",
          "cleanup": "none",
          "sourceIdKey": "source"
        },
        "outputAnchors": [
          {
            "id": "postgresRecordManager_0-output-postgresRecordManager-Postgres RecordManager|RecordManager",
            "name": "postgresRecordManager",
            "label": "Postgres RecordManager",
            "description": "Use Postgres to keep track of document writes into the vector databases",
            "type": "Postgres RecordManager | RecordManager"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 625,
      "selected": false,
      "positionAbsolute": {
        "x": 203.3963175306801,
        "y": -167.5152079120309
      },
      "dragging": false
    },
    {
      "id": "apiLoader_0",
      "position": {
        "x": -450.6325396719673,
        "y": -130.574102290022
      },
      "type": "customNode",
      "data": {
        "id": "apiLoader_0",
        "label": "API Loader",
        "version": 1,
        "name": "apiLoader",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from an API",
        "inputParams": [
          {
            "label": "Method",
            "name": "method",
            "type": "options",
            "options": [
              {
                "label": "GET",
                "name": "GET"
              },
              {
                "label": "POST",
                "name": "POST"
              }
            ],
            "id": "apiLoader_0-input-method-options"
          },
          {
            "label": "URL",
            "name": "url",
            "type": "string",
            "id": "apiLoader_0-input-url-string"
          },
          {
            "label": "Headers",
            "name": "headers",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "apiLoader_0-input-headers-json"
          },
          {
            "label": "Body",
            "name": "body",
            "type": "json",
            "description": "JSON body for the POST request. If not specified, agent will try to figure out itself from AIPlugin if provided",
            "additionalParams": true,
            "optional": true,
            "id": "apiLoader_0-input-body-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "apiLoader_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
          "method": "GET",
          "url": "https://www.who.int/data/gho/info/gho-odata-api",
          "headers": "",
          "body": ""
        },
        "outputAnchors": [
          {
            "id": "apiLoader_0-output-apiLoader-Document",
            "name": "apiLoader",
            "label": "Document",
            "description": "Load data from an API",
            "type": "Document"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 478,
      "selected": false,
      "positionAbsolute": {
        "x": -450.6325396719673,
        "y": -130.574102290022
      },
      "dragging": false
    },
    {
      "id": "chatHuggingFace_0",
      "position": {
        "x": 938.8296664976308,
        "y": -135.79393965046137
      },
      "type": "customNode",
      "data": {
        "id": "chatHuggingFace_0",
        "label": "ChatHuggingFace",
        "version": 2,
        "name": "chatHuggingFace",
        "type": "ChatHuggingFace",
        "baseClasses": [
          "ChatHuggingFace",
          "BaseChatModel",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around HuggingFace large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "chatHuggingFace_0-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "model",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "gpt2",
            "id": "chatHuggingFace_0-input-model-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/gpt2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "chatHuggingFace_0-input-endpoint-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "description": "Temperature parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "description": "Top Probability parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-topP-number"
          },
          {
            "label": "Top K",
            "name": "hfTopK",
            "type": "number",
            "step": 0.1,
            "description": "Top K parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-hfTopK-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "description": "Frequency Penalty parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-frequencyPenalty-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatHuggingFace_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "endpoint": "https://huggingface.co/inference-endpoints",
          "temperature": "0.3",
          "maxTokens": "250",
          "topP": "",
          "hfTopK": "",
          "frequencyPenalty": "100"
        },
        "outputAnchors": [
          {
            "id": "chatHuggingFace_0-output-chatHuggingFace-ChatHuggingFace|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "chatHuggingFace",
            "label": "ChatHuggingFace",
            "description": "Wrapper around HuggingFace large language models",
            "type": "ChatHuggingFace | BaseChatModel | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 577,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 938.8296664976308,
        "y": -135.79393965046137
      }
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 1517.1894900851385,
        "y": -123.6997962796909
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 3,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatHuggingFace_0.data.instance}}",
          "vectorStoreRetriever": "{{postgres_0.data.instance}}",
          "memory": "",
          "returnSourceDocuments": true,
          "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "I'm ready to assist you with your question! I'll carefully review the provided information from the PDF and do my best to provide a comprehensive and accurate answer only from the PDF context.\n**Here's the context I'll be using:**\n {context}\n {question}\n**Please ensure your response adheres to the following guidelines:**\n- Begin with a friendly and professional greeting.\n- Structure the answer in a clear bullet-point format.\n- Aim for a minimum of 100 words, while keeping it concise - Prioritize information found within the database.\n- If you're unable to determine a definitive answer, acknowledge this honestly and do not suggest potential resources or alternative approaches.\n- ****If the question is not related to the context:****\n    -**Remove html and css tags if present in the context before answering.\n    -**Do not greet and not to say anything.\n    -**Do not structure the answer in bullet-point format if no answer found.\n    -**Do not attempt the question using general knowledge.\n    - Clearly state in one line that the question is outside the scope of your knowledge base and don't suggest anything and wrap up in single line.\n    - Do not attempt to answer the question using external information.\n**Important:** Please focus solely on the information within the given context and database. Do not introduce any external knowledge or search for answers online. Your response must directly address the question based on the provided context and database content.\n****Do not repeat the same context again again.****\nI'm committed to providing you with the most helpful and accurate information possible. Let's get started!",
          "inputModeration": []
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 532,
      "selected": false,
      "positionAbsolute": {
        "x": 1517.1894900851385,
        "y": -123.6997962796909
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "huggingFaceInferenceEmbeddings_0",
      "sourceHandle": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
      "target": "postgres_0",
      "targetHandle": "postgres_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "huggingFaceInferenceEmbeddings_0-huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings-postgres_0-postgres_0-input-embeddings-Embeddings"
    },
    {
      "source": "postgresRecordManager_0",
      "sourceHandle": "postgresRecordManager_0-output-postgresRecordManager-Postgres RecordManager|RecordManager",
      "target": "postgres_0",
      "targetHandle": "postgres_0-input-recordManager-RecordManager",
      "type": "buttonedge",
      "id": "postgresRecordManager_0-postgresRecordManager_0-output-postgresRecordManager-Postgres RecordManager|RecordManager-postgres_0-postgres_0-input-recordManager-RecordManager"
    },
    {
      "source": "recursiveCharacterTextSplitter_0",
      "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "apiLoader_0",
      "targetHandle": "apiLoader_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-apiLoader_0-apiLoader_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "apiLoader_0",
      "sourceHandle": "apiLoader_0-output-apiLoader-Document",
      "target": "postgres_0",
      "targetHandle": "postgres_0-input-document-Document",
      "type": "buttonedge",
      "id": "apiLoader_0-apiLoader_0-output-apiLoader-Document-postgres_0-postgres_0-input-document-Document"
    },
    {
      "source": "chatHuggingFace_0",
      "sourceHandle": "chatHuggingFace_0-output-chatHuggingFace-ChatHuggingFace|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatHuggingFace_0-chatHuggingFace_0-output-chatHuggingFace-ChatHuggingFace|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    },
    {
      "source": "postgres_0",
      "sourceHandle": "postgres_0-output-retriever-Postgres|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "postgres_0-postgres_0-output-retriever-Postgres|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    }
  ]
}